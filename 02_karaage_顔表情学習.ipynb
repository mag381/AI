{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mag381/AI/blob/main/02_karaage_%E9%A1%94%E8%A1%A8%E6%83%85%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtU8eIsOsNcv"
      },
      "source": [
        "# 画像分類\n",
        "\n",
        "画像分類を実践するノートブックです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNgUsGFZBLEh"
      },
      "source": [
        "## 教師データのダウンロード\n",
        "\n",
        "ジャンケンの手の形の教師データをGitHubからダウンロード（Clone）します。\n",
        "\n",
        "2,3行目はダウンロードしたデータから、使用するデータ以外の不要なファイルを削除しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtkx-d0RWnZN"
      },
      "source": [
        "#!git clone https://github.com/karaage0703/janken_dataset datasets\n",
        "#!rm -rf datasets/.git\n",
        "#!rm datasets/LICENSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hKLAhGSCufr"
      },
      "source": [
        "データの中身の確認"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-JSj1Tfaosbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "4nL4XU6Io8i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUU8okD-Cwuo"
      },
      "source": [
        "!ls datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdO2sCkkGXU6"
      },
      "source": [
        "!ls datasets/angry/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63s1idu3Ct_Q"
      },
      "source": [
        "from IPython.display import Image as IPImage\n",
        "from IPython.display import display_jpeg\n",
        "#display_jpeg(IPImage('datasets/angry/***.jpg'))\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "metadata": {
        "id": "e09pWM_1skyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "DDISR9uUuMzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets"
      ],
      "metadata": {
        "id": "h6GnQ4lMuq6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWdaU-dW4kvI"
      },
      "source": [
        "## 教師データを訓練データ（Train Data）とテストデータ（Validation Data）に分割"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPVitbmqrXgi"
      },
      "source": [
        "ディレクトリの構造を可視化するための`tree`というソフトをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA0Me7ARH3gJ"
      },
      "source": [
        "!sudo apt install tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0h2uglmIzQv"
      },
      "source": [
        "!tree -d datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zmdetFKFvWp"
      },
      "source": [
        "教師データのディレクトリと、ターゲットとなるディレクトリ（この下に訓練データのディレクトリと検証データのディレクトリが生成される）を指定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA4SGY54GY6b"
      },
      "source": [
        "dataset_original_dir = 'datasets'\n",
        "dataset_root_dir = 'target_datasets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kevX13wW47Ub"
      },
      "source": [
        "教師データを訓練データのディレクトリ(train)と検証データのディレクトリ（val）に分割するスクリプトをダウンロードします。\n",
        "\n",
        "スクリプトのプログラムに関しては、本ノートブックの主題では無いので割愛します。興味ある方は以下のアドレスで、ソフトの中身を確認して下さい。\n",
        "\n",
        "https://raw.githubusercontent.com/karaage0703/karaage-ai-book/master/util/split_train_val.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGSRbbuIreaQ"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/karaage0703/karaage-ai-book/master/util/split_train_val.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U17652B6BMbY"
      },
      "source": [
        "import split_train_val\n",
        "split_train_val.image_dir_train_val_split(\n",
        "    dataset_original_dir, dataset_root_dir, train_size=0.67)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHugFL3VIJfb"
      },
      "source": [
        "!tree -d target_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVNXMfrLD97Y"
      },
      "source": [
        "!ls target_datasets/train/angry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3-W-iIAEDXc"
      },
      "source": [
        "!ls target_datasets/val/angry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3PHCUYZJd-W"
      },
      "source": [
        "train_dir = 'target_datasets/train'\n",
        "val_dir = 'target_datasets/val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roHDM7MB1w9S"
      },
      "source": [
        "## ラベルファイルの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSq7-H5b2DVx"
      },
      "source": [
        "学習するファイルのラベルを作成します"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN5gSnfyz7Tp"
      },
      "source": [
        "必要なライブラリをインポートします"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQkx3zp1Pwt"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjsFU39e3ncO"
      },
      "source": [
        "データを保存する場所を指定します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UhMCgO53m4M"
      },
      "source": [
        "backup_dir = './model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKkS5ed_Jx6c"
      },
      "source": [
        "ラベルデータを作成します（最後に表示される class numberが画像の種類の数です）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRk9ZAWZlj9C"
      },
      "source": [
        "labels = [d for d in os.listdir(dataset_original_dir) \\\n",
        "    if os.path.isdir(os.path.join(dataset_original_dir, d))]\n",
        "labels.sort()\n",
        "\n",
        "if os.path.exists(backup_dir):\n",
        "  shutil.rmtree(backup_dir)\n",
        "\n",
        "os.makedirs(backup_dir)\n",
        "\n",
        "with open(backup_dir + '/labels.txt','w') as f:\n",
        "  for label in labels:\n",
        "    f.write(label+\"\\n\")\n",
        "\n",
        "NUM_CLASSES = len(labels)\n",
        "print(\"class number=\" + str(NUM_CLASSES))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzE-lgUNJ3e8"
      },
      "source": [
        "ラベルを確認します。ラベル名（choki, gu, pa）が並んでいればOKです"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRBOzF1i6HnT"
      },
      "source": [
        "!cat ./model/labels.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLcN1JHv2Q6g"
      },
      "source": [
        "## 学習の事前準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gDNFkOpyQ0C"
      },
      "source": [
        "### ライブラリのインポート"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln1wU_8DFe22"
      },
      "source": [
        "必要なライブラリをインポートします\n",
        "\n",
        "このNotebookはTensorFlow、2.x系で動作するので、TensorFlow 2.x系を選択してインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ltMN9XGBqSa"
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDmuYdo-BnJK"
      },
      "source": [
        "続いて、他に必要なライブラリをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvUS5Z5CEjQp"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwz5rPa333ch"
      },
      "source": [
        "先ほど作成したラベルファイルから、ラベル情報を読み込みます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkbhFC1Dxrb-"
      },
      "source": [
        "labels = []\n",
        "with open(backup_dir + '/labels.txt','r') as f:\n",
        "  for line in f:\n",
        "    labels.append(line.rstrip())\n",
        "print(labels)\n",
        "\n",
        "NUM_CLASSES = len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyuTS7gwyVP0"
      },
      "source": [
        "### 学習のハイパーパラメータの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E3MR7dzTddI"
      },
      "source": [
        "学習のハイパーパラメータの設定をします"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBSQYa3QE9jQ"
      },
      "source": [
        "# 学習率\n",
        "LEARNING_RATE = 0.001\n",
        "# エポック（世代数）\n",
        "EPOCHS = 20\n",
        "# バッチサイズ\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRKlr-AcTVEn"
      },
      "source": [
        "### データセットの前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaT6RgL5yeYQ"
      },
      "source": [
        "データセットの前処理（変換）をします"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP3ogIEXGQzf"
      },
      "source": [
        "IMAGE_SIZE = 64\n",
        "\n",
        "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "val_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_data_gen.flow_from_directory(\n",
        "    train_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    color_mode='rgb', batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', shuffle=True)\n",
        "\n",
        "validation_data = val_data_gen.flow_from_directory(\n",
        "    val_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    color_mode='rgb', batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkrwuMQOykJO"
      },
      "source": [
        "### 前処理の確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVicgfQp8z6r"
      },
      "source": [
        "　イテレータを使うと、まとまったデータを順々に処理するのに便利なので、大量のデータを処理するディープラーニングではよく使われます。イテレータに関してより詳しく知りたい方は、Pythonの入門書やWebでの情報を調べてみて下さい。\n",
        "\n",
        "ここでは、イテレータの中身を確認しておきます。イテレータの中身を確認するには next関数を使うのが簡単です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6OJHTv_8BB6"
      },
      "source": [
        "(image_data,label_data) = train_data.__next__()\n",
        "print(image_data)\n",
        "print(label_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-QJyJme-YgW"
      },
      "source": [
        "print(image_data.shape)\n",
        "print(label_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yNNJhWyCrHW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_numb = 6 # 3の倍数を指定してください\n",
        "for i in range(0, image_numb):\n",
        "  ax = plt.subplot(image_numb // 3, 3, i + 1)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title(str(i))\n",
        "  plt.imshow(image_data[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeYkR1giyql0"
      },
      "source": [
        "## AIモデル作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHZhFZp22I1K"
      },
      "source": [
        "ニューラルネットワーク（CNN）モデルを作成します\n",
        "これは、KerasのMNISTと呼ばれる文字認識に使われるニューラルネットワークモデルをベースにしています。\n",
        "\n",
        "MNISTは、0,1の2値ですが、RGB画像に対応できるように改造しています。具体的には、最初の層の入力サイズを `input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)`とすることで対応しています。\n",
        "\n",
        "https://keras.io/examples/mnist_cnn/\n",
        "\n",
        "注：以下のコード、書籍では`lr`となっているところを最新のバージョンの推奨に合わせて`learning_rate`に変更しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W57_jd8K8Ox"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(NUM_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "#opt = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
        "\n",
        "model.compile(opt, loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01E8ayYiGL9T"
      },
      "source": [
        "モデルの概要を確認します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pAr9iyrGNWI"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqLJDFl3rznt"
      },
      "source": [
        "AIモデルの学習を行います"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxzfODkyl5hN"
      },
      "source": [
        "%%time\n",
        "history = model.fit(train_data, epochs=EPOCHS, validation_data=validation_data, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELuHBiwnGIk7"
      },
      "source": [
        "## 学習結果の可視化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZbIQD0KHgFt"
      },
      "source": [
        "lossを確認します。低いほど良い性能を示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Oz6q5XnQGEW"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlim([0.0, EPOCHS])\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SFJtbPg5Hd7"
      },
      "source": [
        "acc（精度）を確認します。accが訓練データでの精度で、この値が高いほど良い性能を意味します。\n",
        "例えば0.5だと50%の正解率ということになります。\n",
        "\n",
        "val_accというのが訓練に使っていないテストデータを使っての精度です。  \n",
        "いわゆる、本当の精度と言われるものは、val_accの方となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nKjkoxfG7Ox"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlim([0.0, EPOCHS])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.legend(['acc', 'val_acc'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vWiax4zg70l"
      },
      "source": [
        "## 学習させたモデルを使った推定\n",
        "\n",
        "学習させたモデルを使って、画像の推定を行います"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy5DOL0JUQar"
      },
      "source": [
        "# Get the ordered list of class names:\n",
        "import PIL.Image as Image\n",
        "class_names = validation_data.class_indices.items()\n",
        "class_names = np.array([key.title() for key, value in class_names])\n",
        "\n",
        "validation_data.reset()\n",
        "validation_data.shuffle = True\n",
        "validation_data.batch_size = BATCH_SIZE\n",
        "\n",
        "# Retrieve the first batch from the validation data\n",
        "for validation_image_batch, validation_label_batch in validation_data:\n",
        "  break\n",
        "\n",
        "validation_id = np.argmax(validation_label_batch, axis=-1)\n",
        "validation_label = class_names[validation_id]\n",
        "predicted_batch = model.predict(validation_image_batch)\n",
        "\n",
        "# Returns the indices of the maximum values along a given axis\n",
        "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
        "\n",
        "# Return the maximum values along a given axis\n",
        "predicted_score = np.max(predicted_batch, axis=-1)\n",
        "\n",
        "predicted_label_batch = class_names[predicted_id]\n",
        "\n",
        "plt.figure(figsize=(16, 9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Display the classification results for the first 30 images\n",
        "for n in range(min(validation_image_batch.shape[0], 30)):\n",
        "  plt.subplot(6, 5, n + 1)\n",
        "\n",
        "  # Convert the range from -1 to 1 to the range from 0 to 1\n",
        "  plt.imshow(np.array(validation_image_batch[n]*255,np.int32))\n",
        "  color = 'green' if predicted_id[n] == validation_id[n] else 'red'\n",
        "  predicted_label = predicted_label_batch[n].title()\n",
        "  plt.title(predicted_label + ' ({:.2f}, {})'.format(\n",
        "      predicted_score[n], validation_label[n]), color=color)\n",
        "  plt.axis('off')\n",
        "\n",
        "_ = plt.suptitle('Model predictions (green: correct, red: incorrect)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7h85uRoRODs"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "validation_data.reset()\n",
        "validation_data.shuffle =  False\n",
        "validation_data.batch_size = 1\n",
        "\n",
        "# Retrieve the first batch from the validation data\n",
        "for validation_image_batch, validation_label_batch in validation_data:\n",
        "  break\n",
        "\n",
        "predicted = model.predict(validation_data, steps=validation_data.n)\n",
        "predicted_classes = np.argmax(predicted, axis=-1)\n",
        "\n",
        "# Apply normalization\n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "cm = confusion_matrix(validation_data.classes, predicted_classes)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(12, 9))\n",
        "\n",
        "# https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "# https://matplotlib.org/users/colormaps.html\n",
        "sns.heatmap(cm, annot=True, square=True, cmap=plt.cm.Blues,\n",
        "            xticklabels=validation_data.class_indices,\n",
        "            yticklabels=validation_data.class_indices)\n",
        "\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.xlim([0.0, 3.0])\n",
        "plt.ylim([0.0, 3.0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD25Q-GQOmdg"
      },
      "source": [
        "## 学習モデルの保存と読み込み\n",
        "\n",
        "\n",
        "Google Colaboratory上のファイルは、自動的に消えてしまうのでファイルを保存します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW0cyDqaoc5u"
      },
      "source": [
        "save_model_path = os.path.join(backup_dir, 'my_model.h5')\n",
        "model.save(save_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QmNcAlLpwwU"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqlA0xCoqC-y"
      },
      "source": [
        "!ls model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ezVnJDpy4a"
      },
      "source": [
        "!cp './model/my_model.h5' '/content/drive/MyDrive'\n",
        "!cp './model/labels.txt' '/content/drive/MyDrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZPa6nEnoglz"
      },
      "source": [
        "あとは、Google Drive経由でファイルをダウンロードします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3jKFzqu-00L"
      },
      "source": [
        "## まとめ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-BVvtN2aqKX"
      },
      "source": [
        "ここまでで、学習から推論は完了です。\n",
        "\n",
        "発展として、以下を実施してどうなるか確認してみましょう。\n",
        "\n",
        "- ハイパーパラメータを変更して学習の変更度合いを確認\n",
        "- 教師データをジャンケン以外のものにしてみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3H26WGdKAze"
      },
      "source": [
        "## 参考リンク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7UIdrA1KFlO"
      },
      "source": [
        "以下は多くを参考にした情報です。\n",
        "\n",
        "CNN構造\n",
        "- http://aidiary.hatenablog.com/entry/20161127/1480240182\n",
        "\n",
        "\n",
        "データN増し\n",
        "- https://github.com/bohemian916/deeplearning_tool/blob/master/increase_picture.py\n",
        "\n",
        "GradCam\n",
        "- https://github.com/shinmura0/Python-study-group/blob/master/Text3.ipynb\n",
        "\n",
        "GradCam Confusion Matrix\n",
        "- https://colab.research.google.com/drive/1mirG8BSoB3k87mh-qyY3-8-ZXj0XB6h6\n",
        "\n",
        "TensorFlow 2.x対応\n",
        "- http://tensorflow.classcat.com/2019/11/04/tf20-tutorials-images-classification/\n",
        "\n",
        "乱数(Seed)固定\n",
        "- https://scrapbox.io/nwtgck/Tensorflow+Keras%E3%81%A7%E5%86%8D%E7%8F%BE%E6%80%A7%E3%81%AE%E3%81%82%E3%82%8B%E4%B9%B1%E6%95%B0%E3%82%92%E7%94%9F%E6%88%90%E3%81%99%E3%82%8B_-_%E3%82%B7%E3%83%BC%E3%83%89%E5%9B%BA%E5%AE%9A\n",
        "- https://qiita.com/okotaku/items/8d682a11d8f2370684c9\n",
        "\n",
        "\n",
        "以下は、ヒントとなった情報\n",
        "- http://aidiary.hatenablog.com/entry/20161212/1481549365\n",
        "- https://qiita.com/yampy/items/706d44417c433e68db0d\n",
        "- https://qiita.com/haru1977/items/17833e508fe07c004119\n",
        "- http://hatakazu.hatenablog.com/entry/2017/06/08/045953\n",
        "- https://qiita.com/Mco7777/items/2b76aba1bae35f2623ea\n",
        "\n"
      ]
    }
  ]
}